{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src/models/')\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "# import pandas as pd\n",
    "\n",
    "from src.code_snippets.dataprep.embeddings_preprocessing.data_preparation import (\n",
    "    sentences_to_indices,\n",
    "    pretrained_embedding_layer\n",
    ")\n",
    "\n",
    "from src.code_snippets.utils.abstract_classes import Trainer\n",
    "from src.code_snippets.dataprep.embeddings_preprocessing.glove.reader import read_glove_file,get_word_index_dicts\n",
    "from src.code_snippets.dataprep.embeddings_preprocessing.data_preparation import pretrained_embedding_layer\n",
    "import random\n",
    "from src.code_snippets.utils.data_handler import read_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ManyToOneSeqModel(Trainer):\n",
    "\n",
    "    def __init__(self,train_data,val_data,embedding_dir):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.embedding_dir = embedding_dir\n",
    "        self.gensim_model = read_glove_file(self.embedding_dir)\n",
    "        self.word_to_index,self.index_to_words = get_word_index_dicts(self.gensim_model)\n",
    "        \n",
    "        self.m_X, self.n_X = self.train_data['X_indices_train'].shape\n",
    "        self.m_X_aux, self.n_X_aux = self.train_data['X_aux_train'].shape\n",
    "    \n",
    "    def set_model(self):\n",
    "        pretrained_embedding_layer(self.gensim_model, self.word_to_index)\n",
    "    \n",
    "    def save_model(self):\n",
    "        pass\n",
    "    def fit_model(self):\n",
    "        pass\n",
    "    def generate_metrics(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,LSTM,Conv1D,Dropout, Dense\n",
    "from tensorflow.keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_pickle('../../data/processed/processed_data_train.pickle')\n",
    "val_data = read_pickle('../../data/processed/processed_data_val.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(809, 115)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['X_indices'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler_train = read_pickle('../../data/processed/StandardScaler_train.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = StandardScaler_train.inverse_transform(train_data['X_aux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145.        ,  33.        ,   1.        , ...,   3.03030303,\n",
       "          9.09090909,  27.27272727],\n",
       "       [355.        ,  71.        ,   1.        , ...,   8.45070423,\n",
       "          5.63380282,  26.76056338],\n",
       "       [ 92.        ,  21.        ,   1.        , ...,   0.        ,\n",
       "          4.76190476,  28.57142857],\n",
       "       ...,\n",
       "       [333.        ,  67.        ,   1.        , ...,   2.98507463,\n",
       "          4.47761194,  23.88059701],\n",
       "       [104.        ,  23.        ,   1.        , ...,   8.69565217,\n",
       "          0.        ,   4.34782609],\n",
       "       [370.        ,  92.        ,   1.        , ...,   6.52173913,\n",
       "          8.69565217,  17.39130435]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.ARGmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94778</th>\n",
       "      <td>0fd85e97c0b88732</td>\n",
       "      <td>ASSHOLE \\nYOU ARE AN ASSHOLE WIKI NAZI! \\n\\nFR...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text  \\\n",
       "94778  0fd85e97c0b88732  ASSHOLE \\nYOU ARE AN ASSHOLE WIKI NAZI! \\n\\nFR...   \n",
       "\n",
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "94778      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[raw_train['comment_text'].apply(lambda x: ('FREEDOM' in x)&('ASSHOLE' in x)&('NAZI' in x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.code_snippets.dataprep.embeddings_preprocessing.glove.twitter_preprocessing import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ASSHOLE \\nYOU ARE AN ASSHOLE WIKI NAZI! \\n\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEhttp://en-US.www.mozilla.com/en-US/firefox/central/\\nGetting StartedDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!\\nFREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREEDOM!FREE'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train['comment_text'][94778]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freedom <allcaps>  !freedom <allcaps>  !freedom <allcaps> '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('FREEDOM!FREEDOM!FREEDOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.74700000e+03, 8.50000000e+01, 0.00000000e+00, 4.94117647e+01,\n",
       "       0.00000000e+00, 6.77647059e+02, 1.41176471e+01, 5.05882353e+01,\n",
       "       2.35294118e+00, 0.00000000e+00, 1.17647059e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in train_data['X_indices']:\n",
    "    a.append(i[i!=0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77421\n"
     ]
    }
   ],
   "source": [
    "longest_comment = np.argmax([len(i) for i in a])\n",
    "train_data['X_indices'][longest_comment]\n",
    "print(longest_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.98700e+04, 1.91800e+03, 6.68737e+05, ..., 1.00000e+00,\n",
       "       2.14421e+05, 1.91800e+03])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['X_indices'][longest_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_train= pd.read_csv('../../data/interim/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1293c8bb110e6efc</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b86eae945de4168</td>\n",
       "      <td>\"However, Davis was one of many jazz musicians...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63468eaa2d43cae5</td>\n",
       "      <td>hello \\n\\nim not sure of the proper way to add...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2a3ea8e9e81d99dd</td>\n",
       "      <td>\"I'm in on some controversy.  I came here beca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75ca0bc5b4f4fa70</td>\n",
       "      <td>I changed the subject heading to Talk:Sarah_Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153183</th>\n",
       "      <td>dc1a61190e0475dd</td>\n",
       "      <td>the joy of turning yourself from a Bavarian cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153184</th>\n",
       "      <td>af8962ff812c1748</td>\n",
       "      <td>Image:Garma03.jpg\\nI have tagged Image:Garma03...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153185</th>\n",
       "      <td>d0058dd19c233604</td>\n",
       "      <td>\"\\nTesla stuff\\n\\nNotice how all those \"\"ugly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153186</th>\n",
       "      <td>95df37d4a69b607d</td>\n",
       "      <td>I am assuming that there is no point trying to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153187</th>\n",
       "      <td>668ba87c1b6a3f31</td>\n",
       "      <td>\"\\nPlus, take a look! Have I made  any outing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153188 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       1293c8bb110e6efc  \"\\n\\n Please do not vandalize pages, as you di...   \n",
       "1       6b86eae945de4168  \"However, Davis was one of many jazz musicians...   \n",
       "2       63468eaa2d43cae5  hello \\n\\nim not sure of the proper way to add...   \n",
       "3       2a3ea8e9e81d99dd  \"I'm in on some controversy.  I came here beca...   \n",
       "4       75ca0bc5b4f4fa70  I changed the subject heading to Talk:Sarah_Pa...   \n",
       "...                  ...                                                ...   \n",
       "153183  dc1a61190e0475dd  the joy of turning yourself from a Bavarian cr...   \n",
       "153184  af8962ff812c1748  Image:Garma03.jpg\\nI have tagged Image:Garma03...   \n",
       "153185  d0058dd19c233604  \"\\nTesla stuff\\n\\nNotice how all those \"\"ugly ...   \n",
       "153186  95df37d4a69b607d  I am assuming that there is no point trying to...   \n",
       "153187  668ba87c1b6a3f31  \"\\nPlus, take a look! Have I made  any outing ...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "153183      0             0        0       0       0              0  \n",
       "153184      0             0        0       0       0              0  \n",
       "153185      0             0        0       0       0              0  \n",
       "153186      0             0        0       0       0              0  \n",
       "153187      0             0        0       0       0              0  \n",
       "\n",
       "[153188 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[raw_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.features.build_features.textProcessor at 0x7f0ba92a4c88>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tp.st.tokenize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import textProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 17:52:27.652818 139690821285696 api.py:40] HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0ba926b438>: Failed to establish a new connection: [Errno 111] Connection refused')), retrying in 3 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 17:52:30.656558 139690821285696 api.py:40] HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0ba926bc50>: Failed to establish a new connection: [Errno 111] Connection refused')), retrying in 3 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 17:52:33.662531 139690821285696 api.py:40] HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0ba92484a8>: Failed to establish a new connection: [Errno 111] Connection refused')), retrying in 3 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 17:52:36.667307 139690821285696 api.py:40] HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0ba926bf60>: Failed to establish a new connection: [Errno 111] Connection refused')), retrying in 3 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 17:52:39.671648 139690821285696 api.py:40] HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cssplit%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0ba926ba90>: Failed to establish a new connection: [Errno 111] Connection refused')), retrying in 3 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing connection...\n",
      "testing connection...\n",
      "Server ready!\n"
     ]
    }
   ],
   "source": [
    "tp = textProcessor(\n",
    "    data_dir='../../data/interim/val.csv',\n",
    "    # TODO: Change embedding size\n",
    "    embedding_dir='../../data/raw/pretrained_embeddings/glove.twitter.27B/glove.twitter.27B.25d.txt',\n",
    "    nrows=1000,\n",
    ")\n",
    "\n",
    "tp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "st = CoreNLPParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.clean(\"comment_text\", \"comment_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.post_processing_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " \"'m\",\n",
       " 'lifting',\n",
       " 'a',\n",
       " 'glass',\n",
       " ',',\n",
       " 'myself',\n",
       " '.',\n",
       " 'Voting',\n",
       " 'just',\n",
       " 'ended',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Italian',\n",
       " 'page',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'page',\n",
       " 'is',\n",
       " 'maintained',\n",
       " '.',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'your',\n",
       " 'help',\n",
       " 'and',\n",
       " 'advice',\n",
       " '!']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(st.tokenize(tp.df.iloc[659]['comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asshole',\n",
       " '<allcaps>',\n",
       " 'you',\n",
       " '<allcaps>',\n",
       " 'are',\n",
       " '<allcaps>',\n",
       " 'an',\n",
       " '<allcaps>',\n",
       " 'asshole',\n",
       " '<allcaps>',\n",
       " 'wiki',\n",
       " '<allcaps>',\n",
       " 'nazi',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'free',\n",
       " '<allcaps>',\n",
       " '<url>',\n",
       " '/',\n",
       " 'getting',\n",
       " '<unknown>',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " '!',\n",
       " 'freedom',\n",
       " '<allcaps>',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tp.index_to_words[i] for i in train_data['X_indices'][longest_comment] if i!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00000e+00, 4.82744e+05, 1.62203e+05, 4.24731e+05, 6.34784e+05,\n",
       "       4.60382e+05, 1.73600e+03, 3.77230e+04, 6.68737e+05, 1.52288e+05,\n",
       "       6.55001e+05, 6.02843e+05, 1.75537e+05, 6.07686e+05, 6.09967e+05,\n",
       "       6.52183e+05, 1.81800e+03, 2.68863e+05, 6.68737e+05, 1.22517e+05,\n",
       "       6.07686e+05, 1.62203e+05, 5.63885e+05, 1.73600e+03, 6.68737e+05,\n",
       "       6.54139e+05, 5.91040e+04, 7.49640e+04, 2.15709e+05, 1.75571e+05,\n",
       "       1.81800e+03, 9.83925e+05, 2.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "       0.00000e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['X_indices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224\n"
     ]
    }
   ],
   "source": [
    "num_observations = len(train_data['X_aux_train'])\n",
    "idx = np.arange(num_observations)\n",
    "\n",
    "sample_portion = 0.01\n",
    "sample_size = int(num_observations*sample_portion)\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "sampled_idx = np.random.choice(idx,sample_size,replace = False)\n",
    "\n",
    "use_sample = False\n",
    "\n",
    "if use_sample:\n",
    "    train_data['X_indices_train'] = train_data['X_indices_train'][sampled_idx]\n",
    "    train_data['X_aux_train'] = train_data['X_aux_train'][sampled_idx]\n",
    "    train_data['y_train'] = train_data['y_train'][sampled_idx]\n",
    "else:\n",
    "    train_data['X_indices_train'] = train_data['X_indices_train']\n",
    "    train_data['X_aux_train'] = train_data['X_aux_train']\n",
    "    train_data['y_train'] = train_data['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ManyToOneSeqModel(train_data,\n",
    "                            val_data,\n",
    "                            \"../../data/raw/pretrained_embeddings/glove.twitter.27B/glove.twitter.27B.50d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: uncomment this below\n",
    "#sentence_indices = Input((trainer.n_X),dtype='int32')\n",
    "sentence_indices = Input((100),dtype='int32')\n",
    "\n",
    "\n",
    "# Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "embedding_layer = pretrained_embedding_layer(trainer.gensim_model,\n",
    "                                             trainer.word_to_index)\n",
    "\n",
    "# Propagate sentence_indices through your embedding layer\n",
    "# (See additional hints in the instructions).\n",
    "embeddings = embedding_layer(sentence_indices)   \n",
    "\n",
    "X = LSTM(128,return_sequences=True)(embeddings)\n",
    "\n",
    "X = Dropout(0.1,seed= seed)(X)\n",
    "\n",
    "X = LSTM(128,return_sequences=False)(X)\n",
    "\n",
    "X = Dropout(0.1,seed= seed)(X)\n",
    "\n",
    "X = Dense(16,activation='relu')(X)\n",
    "\n",
    "X = Dropout(0.1,seed= seed)(X)\n",
    "\n",
    "X = Dense(1,activation='sigmoid')(X)\n",
    "\n",
    "\n",
    "model = Model(sentence_indices,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 50)           59675750  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 128)          91648     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 59,901,063\n",
      "Trainable params: 225,313\n",
      "Non-trainable params: 59,675,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122484, 1870)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_data['X_indices_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.47401718,  2.56124698,  0.35331467,  8.74224234,  1.82307054,\n",
       "       21.76854791,  3.38960009,  5.71984145,  8.26518656,  6.53318328,\n",
       "        5.99123906])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.val_data['X_aux_val'].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5138, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.val_data['X_aux_val'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',metrics = [f1_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1531 samples\n",
      "Epoch 1/50\n",
      "1531/1531 [==============================] - 13s 9ms/sample - loss: 0.3509 - f1_metric: 0.0409\n",
      "Epoch 2/50\n",
      "1531/1531 [==============================] - 9s 6ms/sample - loss: 0.2919 - f1_metric: 0.2399\n",
      "Epoch 3/50\n",
      "1376/1531 [=========================>....] - ETA: 0s - loss: 0.2697 - f1_metric: 0.3746"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-31567006c939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(trainer.train_data['X_indices_train'][:,0:100],\n",
    "          trainer.train_data['y_train'],\n",
    "          epochs=50,\n",
    "          batch_size=2**5,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1531 samples\n",
      "Epoch 1/50\n",
      "1531/1531 [==============================] - 266s 174ms/sample - loss: 0.3504 - f1_metric: 0.0372\n",
      "Epoch 2/50\n",
      "1531/1531 [==============================] - 276s 181ms/sample - loss: 0.2870 - f1_metric: 0.2918\n",
      "Epoch 3/50\n",
      "1531/1531 [==============================] - 262s 171ms/sample - loss: 0.2603 - f1_metric: 0.4333\n",
      "Epoch 4/50\n",
      "1531/1531 [==============================] - 286s 187ms/sample - loss: 0.2319 - f1_metric: 0.4627\n",
      "Epoch 5/50\n",
      "1531/1531 [==============================] - 324s 212ms/sample - loss: 0.2250 - f1_metric: 0.4811\n",
      "Epoch 6/50\n",
      "1531/1531 [==============================] - 345s 225ms/sample - loss: 0.2103 - f1_metric: 0.5469\n",
      "Epoch 7/50\n",
      "1531/1531 [==============================] - 362s 237ms/sample - loss: 0.2050 - f1_metric: 0.5221\n",
      "Epoch 8/50\n",
      "1531/1531 [==============================] - 354s 232ms/sample - loss: 0.1884 - f1_metric: 0.6368\n",
      "Epoch 9/50\n",
      "1531/1531 [==============================] - 289s 189ms/sample - loss: 0.1758 - f1_metric: 0.5916\n",
      "Epoch 10/50\n",
      "1531/1531 [==============================] - 270s 176ms/sample - loss: 0.1642 - f1_metric: 0.6636\n",
      "Epoch 11/50\n",
      "1531/1531 [==============================] - 1115s 728ms/sample - loss: 0.1539 - f1_metric: 0.6147\n",
      "Epoch 12/50\n",
      "1531/1531 [==============================] - 456s 298ms/sample - loss: 0.1461 - f1_metric: 0.6964\n",
      "Epoch 13/50\n",
      "1531/1531 [==============================] - 265s 173ms/sample - loss: 0.1365 - f1_metric: 0.7330\n",
      "Epoch 14/50\n",
      "1531/1531 [==============================] - 2206s 1s/sample - loss: 0.1261 - f1_metric: 0.7469\n",
      "Epoch 15/50\n",
      "1531/1531 [==============================] - 267s 175ms/sample - loss: 0.1107 - f1_metric: 0.7939\n",
      "Epoch 16/50\n",
      "1531/1531 [==============================] - 269s 176ms/sample - loss: 0.1100 - f1_metric: 0.8265\n",
      "Epoch 17/50\n",
      "1531/1531 [==============================] - 285s 186ms/sample - loss: 0.0994 - f1_metric: 0.8034\n",
      "Epoch 18/50\n",
      "1531/1531 [==============================] - 289s 189ms/sample - loss: 0.0782 - f1_metric: 0.8722\n",
      "Epoch 19/50\n",
      "1531/1531 [==============================] - 294s 192ms/sample - loss: 0.1007 - f1_metric: 0.8668\n",
      "Epoch 20/50\n",
      "1531/1531 [==============================] - 297s 194ms/sample - loss: 0.0837 - f1_metric: 0.8414\n",
      "Epoch 21/50\n",
      "1531/1531 [==============================] - 295s 192ms/sample - loss: 0.0566 - f1_metric: 0.8646\n",
      "Epoch 22/50\n",
      "1531/1531 [==============================] - 306s 200ms/sample - loss: 0.0607 - f1_metric: 0.8313\n",
      "Epoch 23/50\n",
      "1531/1531 [==============================] - 307s 200ms/sample - loss: 0.0594 - f1_metric: 0.8866\n",
      "Epoch 24/50\n",
      "1531/1531 [==============================] - 335s 219ms/sample - loss: 0.0423 - f1_metric: 0.9010\n",
      "Epoch 25/50\n",
      "1531/1531 [==============================] - 321s 210ms/sample - loss: 0.0355 - f1_metric: 0.8903\n",
      "Epoch 26/50\n",
      "1531/1531 [==============================] - 316s 207ms/sample - loss: 0.0310 - f1_metric: 0.9480\n",
      "Epoch 27/50\n",
      "1531/1531 [==============================] - 312s 203ms/sample - loss: 0.0391 - f1_metric: 0.9215\n",
      "Epoch 28/50\n",
      "1531/1531 [==============================] - 300s 196ms/sample - loss: 0.0283 - f1_metric: 0.9479\n",
      "Epoch 29/50\n",
      "1531/1531 [==============================] - 303s 198ms/sample - loss: 0.0229 - f1_metric: 0.9582\n",
      "Epoch 30/50\n",
      "1531/1531 [==============================] - 295s 193ms/sample - loss: 0.0368 - f1_metric: 0.9513\n",
      "Epoch 31/50\n",
      "1531/1531 [==============================] - 279s 182ms/sample - loss: 0.0063 - f1_metric: 0.9564\n",
      "Epoch 32/50\n",
      "1531/1531 [==============================] - 276s 180ms/sample - loss: 0.0193 - f1_metric: 0.9200\n",
      "Epoch 33/50\n",
      "1531/1531 [==============================] - 277s 181ms/sample - loss: 0.0181 - f1_metric: 0.9298\n",
      "Epoch 34/50\n",
      "1531/1531 [==============================] - 293s 192ms/sample - loss: 0.0099 - f1_metric: 0.9692\n",
      "Epoch 35/50\n",
      "1531/1531 [==============================] - 282s 184ms/sample - loss: 0.0139 - f1_metric: 0.9681\n",
      "Epoch 36/50\n",
      " 480/1531 [========>.....................] - ETA: 3:31 - loss: 0.0027 - f1_metric: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e1be962f60b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(trainer.train_data['X_indices_train'][:,0:100],\n",
    "          trainer.train_data['y_train'][:,0:100],\n",
    "          epochs=50,\n",
    "          batch_size=2**5,\n",
    "          shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
